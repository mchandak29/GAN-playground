{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverserial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        def block(in_feat,out_feat):\n",
    "            x = []\n",
    "            x.append(nn.Linear(in_feat,out_feat))\n",
    "            x.append(nn.BatchNorm1d(out_feat))\n",
    "            x.append(nn.ReLU(inplace=True)) #replace with leaky relu for better gradients transfer\n",
    "            return x\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(n_latent,128),\n",
    "            *block(128,256),\n",
    "            *block(256,512),\n",
    "            *block(512,1024),\n",
    "            nn.Linear(1024,np.prod(img_shape)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        img = x.view(-1,*img_shape) # batch x channels x H x W\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(np.prod(img_shape),512),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,np.prod(img_shape))\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training options\n",
    "n_latent = 10 #dimension of input Latent vector\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "img_shape = (1,28,28)\n",
    "save_after = 10\n",
    "load = -1 #path to checkpoint\n",
    "\n",
    "# intialize generator and discriminator\n",
    "gen = Generator().cuda()\n",
    "dis = Discriminator().cuda()\n",
    "\n",
    "# define Loss function\n",
    "loss = nn.BCELoss().cuda()\n",
    "\n",
    "# create optimizers \n",
    "optimizer_G = torch.optim.Adam(gen.parameters(),lr=2e-4) #GANs are highly sensitive to LRs\n",
    "optimizer_D = torch.optim.Adam(dis.parameters(),lr=2e-4)\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "        \"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_shape[1:]), transforms.ToTensor(), transforms.Normalize([0], [1])]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    mnist,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# display model params\n",
    "total_params = 0\n",
    "for model in [gen,dis]:\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params+=params\n",
    "#     print(\"params in {} : {}\".format(model,params)) #uncomment for network architecture\n",
    "print(\"Total trainable params: {}\".format(total_params))\n",
    "\n",
    "# summary writer\n",
    "writer = SummaryWriter(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training Loop\n",
    "\n",
    "if(load != -1):\n",
    "    checkpoint = torch.load('checkpoints/'+load)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    global_step = checkpoint['global_step']\n",
    "    gen.load_state_dict(checkpoint['gen_state_dict'])\n",
    "    dis.load_state_dict(checkpoint['dis_state_dict'])\n",
    "    optimizer_G.load_state_dict(checkpoint['genopt_state_dict'])\n",
    "    optimizer_D.load_state_dict(checkpoint['disopt_state_dict'])\n",
    "else:\n",
    "    global_step = 0\n",
    "    start_epoch = 0\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(start_epoch,num_epochs)):\n",
    "    \n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for i,(real_images,label) in enumerate(dataloader):\n",
    "        global_step+=1\n",
    "        \n",
    "        #fake - 0, real -1\n",
    "        real = torch.tensor(np.ones((batch_size,1)),dtype=torch.float,).cuda()\n",
    "        fake = torch.tensor(np.zeros((batch_size,1)),dtype=torch.float).cuda()\n",
    "\n",
    "        #generator training\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        x = torch.Tensor(np.random.normal(size = (batch_size,n_latent))).cuda()\n",
    "        generated_images = gen(x)\n",
    "\n",
    "        g_loss = loss(dis(generated_images),real)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        writer.add_scalar('Generator loss',g_loss,global_step=global_step)\n",
    "\n",
    "        #discriminator training\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = loss(dis(real_images.cuda()),real)\n",
    "        fake_loss = loss(dis(generated_images.detach()),fake)\n",
    "\n",
    "        d_loss = real_loss+fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        writer.add_scalar('Discriminator loss',d_loss,global_step=global_step)\n",
    "    \n",
    "    if not os.path.exists('images'): \n",
    "        os.mkdir('images')\n",
    "    \n",
    "    #saving generated images\n",
    "    gen.eval()\n",
    "    x = torch.Tensor(np.random.normal(size = (16,n_latent))).cuda()\n",
    "    generated_images = gen(x)\n",
    "    save_image(generated_images.data,\"images/{}.png\".format(str(epoch).zfill(4)),nrow=4,normalize=True)\n",
    "\n",
    "    if(epoch % save_after == 0):\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.mkdir('checkpoints')\n",
    " \n",
    "        torch.save({\n",
    "            'epoch':epoch,\n",
    "            'global_step':global_step,\n",
    "            'gen_state_dict': gen.state_dict(),\n",
    "            'dis_state_dict': dis.state_dict(),\n",
    "            'genopt_state_dict': optimizer_G.state_dict(),\n",
    "            'disopt_state_dict': optimizer_D.state_dict()\n",
    "        },'checkpoints/'+str(epoch).zfill(4)+'.pth')\n",
    "\n",
    "       \n",
    "print('Finished Training !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #number of images to be generated\n",
    "n_latent = 10\n",
    "img_shape = (1,28,28)\n",
    "load = '0010.pth'\n",
    "\n",
    "gen = Generator().cuda()\n",
    "\n",
    "checkpoint = torch.load('checkpoints/'+load)\n",
    "gen.load_state_dict(checkpoint['gen_state_dict'])\n",
    "\n",
    "gen.eval()\n",
    "x = torch.Tensor(np.random.normal(size = (n,n_latent))).cuda()\n",
    "generated_images = gen(x)\n",
    "save_image(generated_images.data,\"sample.png\",nrow=int(n**0.5),normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
